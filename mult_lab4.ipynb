{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5482fa28-c687-46d7-988a-76e6b7222561",
   "metadata": {},
   "source": [
    "# ЛР4 (Случайный лес)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4a25f11-07cd-4260-8fac-97a9cf73f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, ParameterGrid, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from collections import Counter\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils import resample\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fd93ca-ca79-45a5-b4d6-90d2cb117763",
   "metadata": {},
   "source": [
    "# Предобработка данных для задачи классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00aeccb0-10be-40a5-895a-d85dba70ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classification = pd.read_csv(r'C:\\Users\\xwxsz\\Desktop\\Video_games_esrb_rating.csv')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "data_classification['title'] = label_encoder.fit_transform(data_classification['title'])\n",
    "data_classification['esrb_rating'] = label_encoder.fit_transform(data_classification['esrb_rating'])\n",
    "\n",
    "X = data_classification.drop('esrb_rating', axis=1) \n",
    "y = data_classification['esrb_rating'] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c72f547-67b3-487e-9499-10aeb15ca02f",
   "metadata": {},
   "source": [
    "# Классификация (бейзлайн)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bffd8d6-965b-451b-a670-7c74042402cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8443271767810027\n",
      "F1-Score: 0.845342626435832\n"
     ]
    }
   ],
   "source": [
    "# Инициализация и обучение модели случайного леса\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Предикт\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Оценка\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # Для многоклассовой классификации используем 'weighted'\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'F1-Score: {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e4328e-cf31-4285-a431-a70b1b493f86",
   "metadata": {},
   "source": [
    "# Классификация (улучшенный бейзлайн)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36597b80-8c0d-4ec2-b4e5-db0dfcf20fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "{'class_weight': 'balanced', 'max_depth': 20, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Accuracy: 0.8522427440633246\n",
      "F1-Score: 0.8528096577802824\n"
     ]
    }
   ],
   "source": [
    "# Инициализация модели случайного леса\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Параметры для поиска оптимальных гиперпараметров\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Количество деревьев\n",
    "    'max_depth': [None, 10, 20, 30],  # Глубина деревьев\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Количество признаков для разделения\n",
    "    'class_weight': [None, 'balanced'],  # Для борьбы с несбалансированными классами\n",
    "}\n",
    "\n",
    "# Используем GridSearchCV для поиска оптимальных гиперпараметров\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, verbose=2, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Лучшие параметры\n",
    "print(f\"{grid_search.best_params_}\")\n",
    "\n",
    "# Предикт\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Оценка\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'F1-Score: {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d100ff-2567-4192-a5db-c77cf50fad02",
   "metadata": {},
   "source": [
    "# Классификация (самостоятельная имплементация)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c848272e-7441-4902-a1d7-ae1599e33570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Загрузка данных\n",
    "data_classification = pd.read_csv(r'C:\\Users\\xwxsz\\Desktop\\Video_games_esrb_rating.csv')\n",
    "\n",
    "# Предобработка данных\n",
    "label_encoder = LabelEncoder()\n",
    "data_classification['title'] = label_encoder.fit_transform(data_classification['title'])\n",
    "data_classification['esrb_rating'] = label_encoder.fit_transform(data_classification['esrb_rating'])\n",
    "\n",
    "X = data_classification.drop('esrb_rating', axis=1).values  # Преобразуем в массив NumPy\n",
    "y = data_classification['esrb_rating'].values\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Реализация дерева решений\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y)\n",
    "\n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        if len(set(y)) == 1:\n",
    "            return y[0]\n",
    "        \n",
    "        if self.max_depth is not None and depth >= self.max_depth:\n",
    "            return self._majority_class(y)\n",
    "\n",
    "        feature_index, threshold = self._best_split(X, y)\n",
    "        if feature_index is None:\n",
    "            return self._majority_class(y)\n",
    "\n",
    "        left_mask = X[:, feature_index] <= threshold\n",
    "        right_mask = ~left_mask\n",
    "\n",
    "        if len(X[left_mask]) == 0 or len(X[right_mask]) == 0:\n",
    "            return self._majority_class(y)\n",
    "\n",
    "        left_tree = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
    "        right_tree = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "\n",
    "        return (feature_index, threshold, left_tree, right_tree)\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        best_gini = float('inf')\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        m, n = X.shape\n",
    "\n",
    "        for feature_index in range(n):\n",
    "            thresholds = np.unique(X[:, feature_index])\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                left_mask = X[:, feature_index] <= threshold\n",
    "                right_mask = ~left_mask\n",
    "\n",
    "                if len(y[left_mask]) == 0 or len(y[right_mask]) == 0:\n",
    "                    continue\n",
    "\n",
    "                gini = self._gini_impurity(y[left_mask], y[right_mask])\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_feature = feature_index\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def _gini_impurity(self, left, right):\n",
    "        left_size = len(left)\n",
    "        right_size = len(right)\n",
    "        total_size = left_size + right_size\n",
    "\n",
    "        def gini_group(group):\n",
    "            counter = Counter(group)\n",
    "            return 1 - sum((count / len(group)) ** 2 for count in counter.values())\n",
    "\n",
    "        gini_left = gini_group(left)\n",
    "        gini_right = gini_group(right)\n",
    "\n",
    "        return (left_size / total_size) * gini_left + (right_size / total_size) * gini_right\n",
    "\n",
    "    def _majority_class(self, y):\n",
    "        return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_single(x, self.tree) for x in X])\n",
    "\n",
    "    def _predict_single(self, x, tree):\n",
    "        if isinstance(tree, tuple):\n",
    "            feature_index, threshold, left_tree, right_tree = tree\n",
    "            if x[feature_index] <= threshold:\n",
    "                return self._predict_single(x, left_tree)\n",
    "            else:\n",
    "                return self._predict_single(x, right_tree)\n",
    "        else:\n",
    "            return tree\n",
    "\n",
    "# Реализация случайного леса\n",
    "class MyRandomForestClassifier:\n",
    "    def __init__(self, n_estimators=100, max_depth=None, random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.random_state = random_state\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        np.random.seed(self.random_state)\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(self._train_tree, X, y) for _ in range(self.n_estimators)]\n",
    "            self.trees = [future.result() for future in futures]\n",
    "\n",
    "    def _train_tree(self, X, y):\n",
    "        idx = np.random.choice(len(X), size=len(X), replace=True)\n",
    "        X_sample, y_sample = X[idx], y[idx]\n",
    "\n",
    "        tree = DecisionTree(max_depth=self.max_depth)\n",
    "        tree.fit(X_sample, y_sample)\n",
    "        return tree\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return np.array([Counter(pred).most_common(1)[0][0] for pred in predictions.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11ab9f0d-9987-4c79-949f-9d9648e06b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7994722955145118\n",
      "F1-score: 0.8008441273593092\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели случайного леса\n",
    "rf = MyRandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Оценка модели\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Вывод результатов\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1-score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a787542-fc4e-48e3-b9bd-53b3125193fc",
   "metadata": {},
   "source": [
    "# Предобработка данных для задачи регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fc1a0e3-2f8c-4193-8c19-99880d0851b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_regression = pd.read_excel(r'C:\\Users\\xwxsz\\Desktop\\Real estate valuation data set.xlsx')\n",
    "X = data_regression.drop(columns=['Y house price of unit area'])\n",
    "y = data_regression['Y house price of unit area']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a856a3-1792-4a98-8f12-3631332302de",
   "metadata": {},
   "source": [
    "# Регрессия (бейзлайн)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e3647c3-2da7-4b87-b669-a01943c1b34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 3.8787951807228906\n",
      "R^2: 0.8101253381007657\n"
     ]
    }
   ],
   "source": [
    "# Создание модели случайного леса\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Предикт\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Оценка\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'MAE: {mae}')\n",
    "print(f'R^2: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f6f8f9-4c26-4c6a-8a39-3fb44d25ec23",
   "metadata": {},
   "source": [
    "# Регрессия (улучшенный бейзлайн)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf313f25-fb4f-4794-ad21-8744312b30e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "MAE: 3.6110411685080823\n",
      "R²: 0.8291237493563459\n"
     ]
    }
   ],
   "source": [
    "# Определение модели случайного леса\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Параметры для поиска\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Количество деревьев\n",
    "    'max_depth': [None, 10, 20, 30],  # Максимальная глубина дерева\n",
    "    'min_samples_split': [2, 5, 10],  # Минимальное количество образцов для разделения\n",
    "    'min_samples_leaf': [1, 2, 4],  # Минимальное количество образцов в листьях\n",
    "    'max_features': ['auto', 'sqrt']  # Количество признаков для использования на каждом узле\n",
    "}\n",
    "\n",
    "# Поиск оптимальных гиперпараметров\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=0, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Лучшая модель\n",
    "print(f'{grid_search.best_params_}')\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Предикт\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Оценка\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'MAE: {mae}')\n",
    "print(f'R²: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d81d45a-9bf6-430c-985b-04741c104d10",
   "metadata": {},
   "source": [
    "# Регрессия (самостоятельная имплементация)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bd387a3-428e-4010-8787-6c13633f5ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (до улучшения): 4.734890464561761\n",
      "R^2 (до улучшения): 0.7658082825300714\n"
     ]
    }
   ],
   "source": [
    "class CustomRandomForestRegressor:\n",
    "    def __init__(self, n_estimators=100, max_features=\"sqrt\", max_depth=None, random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.max_depth = max_depth\n",
    "        self.random_state = random_state\n",
    "        self.trees = []\n",
    "        self.features_indices = []\n",
    "\n",
    "    def _bootstrap_sample(self, X, y):\n",
    "        n_samples = X.shape[0]\n",
    "        indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "        return X[indices], y[indices]\n",
    "\n",
    "    def _get_max_features(self, n_features):\n",
    "        if self.max_features == \"sqrt\":\n",
    "            return max(1, int(np.sqrt(n_features)))\n",
    "        elif self.max_features == \"log2\":\n",
    "            return max(1, int(np.log2(n_features)))\n",
    "        elif isinstance(self.max_features, int):\n",
    "            return self.max_features\n",
    "        else:\n",
    "            return n_features\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        np.random.seed(self.random_state)\n",
    "        self.trees = []\n",
    "        self.features_indices = []\n",
    "\n",
    "        # Преобразование DataFrame в NumPy массив\n",
    "        X = X.values if hasattr(X, 'values') else X\n",
    "        y = y.values if hasattr(y, 'values') else y\n",
    "\n",
    "        n_features = X.shape[1]\n",
    "        max_features = self._get_max_features(n_features)\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            X_sample, y_sample = self._bootstrap_sample(X, y)\n",
    "\n",
    "            feature_indices = np.random.choice(n_features, max_features, replace=False)\n",
    "            self.features_indices.append(feature_indices)\n",
    "\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X_sample[:, feature_indices], y_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Преобразование DataFrame в NumPy массив\n",
    "        X = X.values if hasattr(X, 'values') else X\n",
    "\n",
    "        tree_predictions = np.array([\n",
    "            tree.predict(X[:, feature_indices]) for tree, feature_indices in zip(self.trees, self.features_indices)\n",
    "        ])\n",
    "        return tree_predictions.mean(axis=0)\n",
    "\n",
    "rf = CustomRandomForestRegressor(n_estimators=100, max_depth=10)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Предикт\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Оценка\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'MAE (до улучшения): {mae}')\n",
    "print(f'R^2 (до улучшения): {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "157b3aa9-d51e-4c6d-b5ec-da1f50078784",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRandomForestRegressor:\n",
    "    def __init__(self, n_estimators=100, max_features=\"sqrt\", max_depth=None, random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.max_depth = max_depth\n",
    "        self.random_state = random_state\n",
    "        self.trees = []\n",
    "        self.features_indices = []\n",
    "\n",
    "    def _bootstrap_sample(self, X, y):\n",
    "        n_samples = X.shape[0]\n",
    "        indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "        return X[indices], y[indices]\n",
    "\n",
    "    def _get_max_features(self, n_features):\n",
    "        if self.max_features == \"sqrt\":\n",
    "            return max(1, int(np.sqrt(n_features)))\n",
    "        elif self.max_features == \"log2\":\n",
    "            return max(1, int(np.log2(n_features)))\n",
    "        elif isinstance(self.max_features, int):\n",
    "            return self.max_features\n",
    "        else:\n",
    "            return n_features\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        np.random.seed(self.random_state)\n",
    "        self.trees = []\n",
    "        self.features_indices = []\n",
    "\n",
    "        X = X.values if hasattr(X, 'values') else X\n",
    "        y = y.values if hasattr(y, 'values') else y\n",
    "\n",
    "        n_features = X.shape[1]\n",
    "        max_features = self._get_max_features(n_features)\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            X_sample, y_sample = self._bootstrap_sample(X, y)\n",
    "\n",
    "            feature_indices = np.random.choice(n_features, max_features, replace=False)\n",
    "            self.features_indices.append(feature_indices)\n",
    "\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X_sample[:, feature_indices], y_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = X.values if hasattr(X, 'values') else X\n",
    "        tree_predictions = np.array([\n",
    "            tree.predict(X[:, feature_indices]) for tree, feature_indices in zip(self.trees, self.features_indices)\n",
    "        ])\n",
    "        return tree_predictions.mean(axis=0)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return r2_score(y, y_pred)\n",
    "\n",
    "    # Добавление метода get_params\n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            'n_estimators': self.n_estimators,\n",
    "            'max_features': self.max_features,\n",
    "            'max_depth': self.max_depth,\n",
    "            'random_state': self.random_state\n",
    "        }\n",
    "    \n",
    "    # Добавление метода set_params\n",
    "    def set_params(self, **params):\n",
    "        for param, value in params.items():\n",
    "            setattr(self, param, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c812f6d-5b1b-4a2b-93db-15a4a2166da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 150, 'max_features': 5, 'max_depth': None}\n",
      "MAE (после улучшения): 3.694038063364568\n",
      "R^2 (после улучшения): 0.8094543680267501\n"
     ]
    }
   ],
   "source": [
    "# Подбор гиперпараметров с использованием RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'max_features': ['sqrt', 'log2', 5, 10]\n",
    "}\n",
    "\n",
    "# Создание модели случайного леса\n",
    "rf = CustomRandomForestRegressor(random_state=42)\n",
    "\n",
    "# Обучение модели с подбором гиперпараметров\n",
    "random_search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=10, cv=5, scoring='r2', random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Лучшие параметры\n",
    "print(random_search.best_params_)\n",
    "\n",
    "# Предикт\n",
    "y_pred = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Оценка\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'MAE (после улучшения): {mae}')\n",
    "print(f'R^2 (после улучшения): {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b12150-ea04-417b-8f3e-2cc9020a7f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
